[pipeline]
name = "My_Simple_Pipe"
description = "My simple pipeline template - Lego Bricks sample database"
# Database scheme name raw, staging, production etc
schema = "raw"
# Database engine local 'duckdb' or remote 'motherduck' 
database = "duckdb"
#database = "motherduck"

[logging]
level = "INFO"
log_folder = "log"
logfile = "simple_pipe.log"

[task.color_data]
active = true
file_type = "csv"
description = "Load colors.csv file"
url = "data/LegoBricks/colors.csv"
sql_filter = ""
sql_table = "colours"
sql_write = "replace"

[task.elements_data]
active = true
file_type = "csv.filelist"
description = "Process a .cvs file with a list of urls, in this case elements"
url = "data/LegoBricks/elements_urls.csv"
sql_filter = "elements"
sql_table = "elements"
sql_write = "replace"

[task.inventories_data]
active = true
file_type = "csv"
description = "Load inventories.csv file"
url = "data/LegoBricks/inventories.csv"
sql_filter = ""
sql_table = "inventories"
sql_write = "replace"

[task.inventory_minifigs_data]
active = true
file_type = "csv"
description = "Load inventory_minifigs.csv file"
url = "data/LegoBricks/inventory_minifigs.csv"
sql_filter = ""
sql_table = "inventory_minifigs"
sql_write = "replace"

[task.inventory_parts_data]
active = true
file_type = "csv"
description = "Load inventory_parts.csv file"
url = "data/LegoBricks/inventory_parts.csv"
sql_filter = "inventory_parts"
sql_table = "inventory_parts"
sql_write = "replace"

[task.inventory_sets_data]
active = true
file_type = "csv"
description = "Load inventory_sets.csv file"
url = "data/LegoBricks/inventory_sets.csv"
sql_filter = ""
sql_table = "inventory_sets"
sql_write = "replace"

[task.minifigs_data]
active = true
file_type = "csv"
description = "Load minifigs.csv file"
url = "data/LegoBricks/minifigs.csv"
sql_filter = ""
sql_table = "minifigs"
sql_write = "replace"

[task.worksheet_part_categories]
active = true
file_type = "excel"
description = "Extract part_categories from online google sheet in xlsx format"
url = "https://docs.google.com/spreadsheets/d/e/2PACX-1vSRopkzwpUEk9CeRA9AS09ln8YxbJ_7c28BbXCzBvW15OLEPkGlVPBzF8LQCLInvYfjE6LEw__LSorl/pub?output=xlsx"
workbook = "Part Categories"
skiprows = 4
columns = "a:b"
sql_filter = ""
sql_table = "part_categories"
sql_write = "replace"

[task.part_relationships_data]
active = true
file_type = "csv"
description = "Load part_relationships.csv file"
url = "data/LegoBricks/part_relationships.csv"
sql_filter = ""
sql_table = "part_relationships"
sql_write = "replace"

[task.parts_data]
active = true
file_type = "csv"
description = "Load parts.csv file"
url = "data/LegoBricks/parts.csv"
sql_filter = ""
sql_table = "parts"
sql_write = "replace"

[task.sets_data]
active = true
file_type = "csv"
description = "Load sets.csv file"
url = "data/LegoBricks/sets.csv"
sql_filter = ""
sql_table = "sets"
sql_write = "replace"

[task.themes_data]
active = true
file_type = "csv"
description = "Load themes.csv file"
url = "data/LegoBricks/themes.csv"
sql_filter = ""
sql_table = "themes"
sql_write = "replace"

[duckdb.credentials]
# local duckdb database name. Remote motherduck credentials are stored in secret.toml
path = "data"
database = "simple_pipe.duckdb"

[motherduck.credentials]
# local duckdb database name. Remote motherduck credentials are stored in secret.toml
path = ""
database = "simple_pipe"

#SQL Filter statements, filter the df_upload DataFrame
[sql.elements]
sql = """
        SELECT
                "element_id",
                "part_num",
                "color_id" AS "colour_id"
        FROM df_upload
"""

[sql.inventory_parts]
sql ="""
        SELECT
                "inventory_id",
                "part_num",
                "color_id" AS "colour_id",
                "quantity",
                "is_spare",
                "img_url"
        FROM df_upload
"""

