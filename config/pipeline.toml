[pipeline]
name = "My_Simple_Pipe"
description = "My simple pipeline template"
# Database scheme name raw, staging, production etc
schema = "raw"
# Database engine local 'duckdb' or remote 'motherduck' 
database = "duckdb"
#database = "motherduck"

[logging]
level = "INFO"
log_folder = "log/"
logfile = "simple_pipe.log"

[task.merged_data]
active = false
file_type = "csv"
url = "data/merge_data.csv"
# SQL filter on the DataFrame df_load eg.
# sql_filter = 'name_of_filter'
sql_filter = "log_filter"
sql_table = "merged_logs"
sql_write = "replace"

[task.worksheet_a]
active = false
file_type = "excel"
description = "Extract online google sheet in xlsx format"
url = "https://docs.google.com/spreadsheets/??????????"
workbook = "workbook name"
skiprows = 4
columns = "a:k"
sql_filter = "log_filter"
sql_table = "log_a"
sql_write = "replace"

[task.worksheet_b]
active = false
file_type = "excel"
description = "Extract online google sheet in xlsx format"
url = "https://docs.google.com/spreadsheets/??????????"
workbook = "another workbook name"
skiprows = 4
columns = "a:k"
sql_filter = "log_filter"
sql_table = "log_a"
sql_write = "append"

[task.date_table]
active = false
file_type = "csv"
description = ""
url = "data/date_table.csv"
sql_filter = "date_select"
sql_table = "dim_dates"
sql_write = "replace"

[duckdb.credentials]
# local duckdb database name. Remote motherduck credentials are stored in secret.toml
path = "data/"
database = "simple_pipe.duckdb"

[motherduck.credentials]
# local duckdb database name. Remote motherduck credentials are stored in secret.toml
path = ""
database = "simple_pipe"

#SQL Filter statements, filter the df_upload DataFrame
[sql.log_filter]
sql = """
SELECT  
        "Date"::DATE as log_date,
        "Unnamed: 7" as description,
        split_part("Unnamed: 7", ' to ', 1) as start_port,
        split_part("Unnamed: 7", ' to ', 2) as end_port,
        "Hours"::INTEGER as motoring_hours,
        "Minutes"::INTEGER as motoring_minutes,
        "Hours.1"::INTEGER as sailing_hours,
        "Minutes.1"::INTEGER as sailing_minutes,
        "Nautical Miles"::DECIMAL(5,2) as nautical_miles,
        IFNULL("Marina"::INTEGER,0) as marina_nights,
        IFNULL("Anchor"::INTEGER,0) as anchoring_nights,
        IFNULL("Mooring"::INTEGER,0) as mooring_nights
FROM df_upload
WHERE description IS NOT NULL
ORDER BY log_date
"""

[sql.date_select]
sql = """
SELECT *
FROM df_upload
WHERE "date" >= '2020-01-01' and "date" < '2024-01-01'
"""